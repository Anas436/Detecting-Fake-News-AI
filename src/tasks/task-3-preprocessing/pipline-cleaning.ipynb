{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#if the environment doesn't contain pyspellchecker and nltk modules use this:\n# pip install pyspellchecker\n# pip install nltk\nimport re\nimport string\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom spellchecker import SpellChecker\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import wordnet\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_words = set(stopwords.words('english'))\n\n\ndef pipline_cleaning_step(text):\n    tokens = re.findall(r'\\b\\w+\\b', text)\n \n    tokens = [token.lower() for token in tokens]\n \n    stemmer = PorterStemmer()\n    tokens = [stemmer.stem(token) for token in tokens]\n \n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token not in stop_words]\n    spell = SpellChecker()\n\n    # Split text into words\n    tokens = text.split()\n\n    # Correct misspelled words\n    corrected_tokens = []\n    for token in tokens:\n        corrected_token = spell.correction(token)\n        if corrected_token is not None:\n            corrected_tokens.append(corrected_token)\n        else:\n            corrected_tokens.append(token)  # Use the original token if no correction is found\n\n    # Join the tokens back into a clean text\n    clean_text = ' '.join(corrected_tokens)\n\n\n    return clean_text","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}